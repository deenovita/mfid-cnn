{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import numpy\n",
    "from numpy import random\n",
    "from numpy import dot\n",
    "from numpy import exp\n",
    "from numpy import sum\n",
    "from numpy import log\n",
    "from numpy import zeros\n",
    "from numpy import float64\n",
    "from numpy import int64\n",
    "from numpy import unravel_index\n",
    "from numpy import max\n",
    "from numpy import argmax\n",
    "from numpy import copy\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "from numpy import array\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(outputs):\n",
    "    \"\"\"\n",
    "    Fungsi cross entropy untuk mendapatkan nilai loss dari nilai hasil deteksi.\n",
    "\n",
    "    :param outputs: nilai hasil deteksi.\n",
    "    :return: nilai loss hasil deteksi.\n",
    "    \"\"\"\n",
    "\n",
    "    loss_value = -log(outputs)\n",
    "\n",
    "    return loss_value\n",
    "\n",
    "def relu_activation(summa_nrc):\n",
    "    \"\"\"\n",
    "    Fungsi aktivasi Rectified Linear Unit (ReLU) untuk melakukan aktifasi pada nilai input.\n",
    "\n",
    "    :param summa_nrc: hasil operasi konvolusi untuk diaktifkan.\n",
    "    :return: nilai hasil aktivasi ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    if summa_nrc > 0:\n",
    "        return summa_nrc\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def derivative_relu(summa_nrc):\n",
    "    \"\"\"\n",
    "    Untuk mencari nilai turunan dari fungsi aktivasi ReLU.\n",
    "\n",
    "    :param summa_nrc: nilai hasil aktivasi ReLU.\n",
    "    :return: nilai hasil turunan ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    if summa_nrc > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def softmax_activation(summa):\n",
    "    \"\"\"\n",
    "    Fungsi aktivasi softmax untuk melakukan aktivasi nilai dari fully connected layer ke dalam bentuk probabilitas.\n",
    "\n",
    "    :param summa: nilai pembobotan di fully connected layer.\n",
    "    :return: nilai hasil aktivasi dalam bentuk probabilitas.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = exp(summa)\n",
    "    denominator = sum(numerator)\n",
    "    softmax_value = numerator / denominator\n",
    "\n",
    "    return softmax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
